---
title: Adversarial Attack Against Fake News Detection NLP Model
summary: Applied different adversarial attack methods to a bidirectional LSTM model to explore the highest attack success rate in comparison to baseline BERTweet model using PyTorch. 


tags:
- Deep Learning
date: "2021-12-07T00:00:00Z"

# Optional external URL for project (replaces project detail page).
external_link: ""


image:
  caption: Photo by rawpixel on Unsplash
  focal_point: Smart

#links:
#- icon: twitter
#  icon_pack: fab
#  name: Follow
#  url: https://twitter.com/georgecushen
  
url_code: ""
url_pdf: ""
url_slides: ""
url_video: ""

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
#slides: example
---

{{< icon name="download" pack="fas" >}} Download {{< staticref "media/CSCI554_Report.pdf" "newtab" >}}Project{{< /staticref >}}.

## Abstract

This paper performed five adversarial techniques from TextAttacks to generate attacks and compared two types of fake news detection models. The experiment results show that TextFooler has the best performance. DeepWordBug is also very powerful but results are visual dissimilar- ity. BAE and PSO both have average per- formance. BAE focuses on sentence-level semantic similarity, which causes the at- tack itself to be less aggressive. PSO is a sememe-based word substitution that can balance the quality and quantity of change, but population-based algorithm is more computationally expensive. The CheckList has the worst performance, be- cause it mostly depends on the quantity and quality of the self-developed search space. Besides, different pre-trained mod- els also leads to difference in method performances. We finally conclude that thorough word embeddings can improve model robustness.


**Keywords** Natural Language Processing, Text Adversarial Attacks, LSTM, Flair, Word Embedding, Model Robustness

